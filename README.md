# Market Scraper Data EA

**Version:** 1.10
**Platform:** MetaTrader 5 (MQL5)
**Copyright:** Traders Capital Team
**Contact:** @loldlm | https://t.me/TradingAlgoritmicoFx

---

## Overview

The **Market Scraper Data EA** is a specialized Expert Advisor designed to collect and store comprehensive market indicator data into an SQLite database. This tool operates on a tick-by-tick basis, capturing market conditions minute-by-minute across multiple timeframes and indicator periods.

The primary purpose is to build a robust dataset for machine learning, backtesting analysis, and pattern recognition by systematically recording:
- Bollinger Bands (BB) data
- Bollinger Bands Percent (BB%) data
- Stochastic Oscillator values
- Market structure patterns based on stochastic movements
- Candle body oscillator and momentum data

## Key Features

### Data Collection
- **Tick-by-tick processing**: Captures market data on every tick within configured spread limits
- **Multi-timeframe analysis**: Monitors 14 different timeframes (M1-H4) simultaneously
- **Multi-period indicators**: Tracks 5-7 different indicator periods (Fibonacci sequence: 5, 8, 13, 21, 34, 55, 89)
- **Signal detection**: Identifies bullish/bearish signals based on stochastic oversold/overbought levels

### Indicators Tracked

1. **Bollinger Bands (BB)**
   - Standard deviation bands
   - Multiple periods and timeframes

2. **Bollinger Bands Percent (BB%)**
   - Position within bands
   - Signal line values
   - Slope detection (up/down)
   - Percentile classification (0-100 range)
   - Trend identification

3. **Stochastic Oscillator**
   - Main line values (K)
   - Signal line values (D)
   - Slope detection for both lines
   - Percentile classification
   - Overbought/oversold detection (>70 / <30)

4. **Stochastic Market Structure**
   - Higher Highs (HH), Higher Lows (HL)
   - Lower Highs (LH), Lower Lows (LL)
   - Structure timestamps and prices
   - Fibonacci retracement levels

5. **Body MA (Candle Body Oscillator)**
   - Candle body size oscillator
   - Moving average of body sizes
   - Body trend (strong/weak)
   - Body vs MA relationship (bullish/bearish)

### Database Storage

All data is stored in a normalized SQLite database with WAL (Write-Ahead Logging) mode for optimal performance. The file is located in `[Terminal_Data]/MQL5/Files/Common/{Database_System_Name}_db.sqlite`.

## Database Architecture

The EA persists data using a hub-and-spoke schema:
- **MarketDatasetsDB** records run-level metadata (symbol, timeframe horizon, tester configuration).
- **SignalParamsDB** stores each signal detected during a run.
- Indicator snapshot tables (`BandsPercentDB`, `StochasticDB`, `BodyMADB`) and structure tables (`StochasticMarketStructureDB`, `ExtremumStatisticsDB`) hang off `SignalParamsDB` via foreign keys.
- All foreign keys use `ON DELETE CASCADE`, so removing a signal in PostgreSQL should also clean up the dependent indicator rows.

### Entity Relationships

- `MarketDatasetsDB (1) ⟶ (N) SignalParamsDB`
- `SignalParamsDB (1) ⟶ (N)` BandsPercentDB, StochasticDB, BodyMADB, StochasticMarketStructureDB, ExtremumStatisticsDB
- Indicator tables are keyed by `(signal_id, timeframe, period)` so they can be de-duplicated by timeframe/period combinations.

### Table Reference (v1.10)

**MarketDatasetsDB**
- `dataset_id TEXT PRIMARY KEY` – UUID (lowercase string) auto-generated by SQLite
- `name TEXT NOT NULL` – strategy/system label
- `source TEXT DEFAULT ''` – e.g. `live`, `tester`
- `notes TEXT DEFAULT ''` – free-form notes persisted from inputs
- `symbol TEXT NOT NULL`, `symbol_digits INTEGER NOT NULL`
- `date_start INTEGER NOT NULL`, `date_end INTEGER NOT NULL` – unix timestamps
- `tester_model TEXT DEFAULT ''` – MT5 tester model description
- `spread_points INTEGER NOT NULL DEFAULT 0`
- `timezone_offset INTEGER NOT NULL DEFAULT 0` – minutes offset to UTC
- `ea_version TEXT DEFAULT ''`, `build INTEGER NOT NULL DEFAULT 0`
- Indexes: `idx_dataset_dates (date_start, date_end)`, `idx_dataset_symbol (symbol)`

**SignalParamsDB**
- `signal_id INTEGER PRIMARY KEY AUTOINCREMENT`
- `dataset_id TEXT NOT NULL` – FK → MarketDatasetsDB(dataset_id)
- `signal_type INTEGER NOT NULL DEFAULT 0` (`0`=NO_SIGNAL, `1`=BULLISH, `2`=BEARISH)
- `signal_state INTEGER NOT NULL DEFAULT 0` (`0`=WAITING, `1`=OPENED, `2`=TRALING)
- `ticket_id TEXT DEFAULT ''` – placeholder for future trade linkage
- `entry_price REAL NOT NULL DEFAULT 0`, `close_price REAL NOT NULL DEFAULT 0`
- `stop_loss REAL NOT NULL DEFAULT 0`, `take_profit REAL NOT NULL DEFAULT 0`
- `lot_size REAL NOT NULL DEFAULT 0`, `raw_profit REAL NOT NULL DEFAULT 0`
- `entry_time INTEGER NOT NULL`, `close_time INTEGER NOT NULL DEFAULT 0`
- Constraints: `UNIQUE(entry_time, signal_type)` prevents duplicates per candle/type
- Indexes: `idx_sp_entry_time_type (entry_time, signal_type)`, `idx_sp_dataset (dataset_id)`

**BandsPercentDB**
- Composite PK `(signal_id, timeframe, period)`
- Stores BB% main line, signal line, slopes, percentiles, trend flags, and raw OHLC-derived BB% (`bb_close_*`, `bb_open_*`, `bb_high_*`, `bb_low_*`) for bars 0-3
- Index: `idx_bands_tf_p (timeframe, period)`

**StochasticDB**
- Composite PK `(signal_id, timeframe, period)`
- Holds stochastic %K/%D, slopes, percentiles, and trend flags for bars 0-3
- Index: `idx_stoch_tf_p (timeframe, period)`

**StochasticMarketStructureDB**
- Composite PK `(signal_id, timeframe, period)`
- Snapshot of the most recent six structures plus the first four Fibonacci levels
- Index: `idx_struct_tf_p (timeframe, period)`

**ExtremumStatisticsDB**
- Composite PK `(signal_id, timeframe, period, extremum_index)`
- Persists up to 13 extrema per timeframe/period with:
  - `intern_*` fields for internal Fibonacci metrics (`intern_fibo_raw_level` is the unrounded value)
  - `extern_*` fields for context across the tracked range
  - Retest zone analytics (`fibo_retest_zone_*`, `*_zone2_*`, `support_retest_*`, `resistance_retest_*`)
  - `structure_type` for EQ/HH/HL/LH/LL classification
- Index: `idx_extremum_stats (signal_id, timeframe, period)`

**BodyMADB**
- Composite PK `(signal_id, timeframe, period)`
- Tracks candle body sizes, moving averages, trend classification, and MA relation for bars 0-3
- Index: `idx_body_ma_tf_p (timeframe, period)`

### Enumerations & Shared Dimensions

- `SignalTypes`: `0`=NO_SIGNAL, `1`=BULLISH, `2`=BEARISH
- `SignalStates`: `0`=WAITING, `1`=OPENED, `2`=TRALING
- `SlopeTypes`: `0`=NO_SLOPE, `1`=UP_SLOPE, `2`=DOWN_SLOPE
- `OscillatorStructureTypes`: `0`=EQ, `1`=HH, `2`=HL, `3`=LH, `4`=LL
- `BodyTrendTypes`: `0`=BODY_UNDEFINED, `1`=STRONG_BODY_TREND, `2`=WEAK_BODY_TREND
- `BodyMATypes`: `0`=BODY_UNDEFINED_MA, `1`=BODY_BULLISH_MA, `2`=BODY_BEARISH_MA

Timeframes follow MT5 enumeration (`0`=PERIOD_CURRENT, `1`=PERIOD_M1, etc.). Periods are typically Fibonacci numbers `[5, 8, 13, 21, 34, 55, 89]` depending on the indicator.

### Transaction & Performance Notes

- Write operations are wrapped in `BEGIN IMMEDIATE` transactions when saving a signal plus all dependent rows.
- PRAGMAs applied on open:
  - `foreign_keys=ON`
  - `automatic_index=ON`
  - `journal_mode=WAL`
  - `synchronous=NORMAL`
  - `wal_autocheckpoint=1000`
  - `busy_timeout=1000`
  - `cache_size=-64000`
  - `page_size=4096`
- Maintain the same transactional boundaries when porting to PostgreSQL to keep inserts idempotent and atomic.

## Rails / PostgreSQL Migration Guide

The current schema maps cleanly onto Rails models. Recommended steps:

1. **Use native UUIDs for datasets.**
   - Enable `enable_extension 'pgcrypto'` (or `uuid-ossp`) and store `dataset_id` as a `uuid` primary key.
   - When importing legacy SQLite rows, cast the stored lowercase UUID strings to PostgreSQL `uuid`.

2. **Mirror enumerations using Rails `enum`.**
   ```ruby
   class Signal < ApplicationRecord
     enum signal_type: { no_signal: 0, bullish: 1, bearish: 2 }
     enum signal_state: { waiting: 0, opened: 1, traling: 2 }
   end
   ```

3. **Create tables with composite keys via surrogate IDs or database constraints.**
   - Rails does not support composite PKs natively; prefer integer surrogate IDs with unique indexes that match the SQLite primary keys, or use the `composite_primary_keys` gem.
   - Suggested approach: keep implicit `id` columns in Rails and add `t.index [:signal_id, :timeframe, :period], unique: true`.

4. **Sample migrations (excerpt).**
   ```ruby
   create_table :market_datasets, id: :uuid do |t|
     t.string  :name, null: false
     t.string  :source, default: ''
     t.text    :notes, default: ''
     t.string  :symbol, null: false
     t.integer :symbol_digits, null: false
     t.bigint  :date_start, null: false
     t.bigint  :date_end, null: false
     t.string  :tester_model, default: ''
     t.integer :spread_points, null: false, default: 0
     t.integer :timezone_offset, null: false, default: 0
     t.string  :ea_version, default: ''
     t.integer :build, null: false, default: 0
     t.timestamps
   end
   add_index :market_datasets, [:date_start, :date_end], name: :idx_dataset_dates
   add_index :market_datasets, :symbol, name: :idx_dataset_symbol

   create_table :signals do |t|
     t.references :market_dataset, type: :uuid, null: false, foreign_key: { on_delete: :cascade }
     t.integer :signal_type, null: false, default: 0
     t.integer :signal_state, null: false, default: 0
     t.string  :ticket_id, default: ''
     t.decimal :entry_price, precision: 16, scale: 6, null: false, default: 0
     t.decimal :close_price, precision: 16, scale: 6, null: false, default: 0
     t.decimal :stop_loss, precision: 16, scale: 6, null: false, default: 0
     t.decimal :take_profit, precision: 16, scale: 6, null: false, default: 0
     t.decimal :lot_size, precision: 12, scale: 2, null: false, default: 0
     t.decimal :raw_profit, precision: 18, scale: 6, null: false, default: 0
     t.bigint  :entry_time, null: false
     t.bigint  :close_time, null: false, default: 0
     t.timestamps
   end
   add_index :signals, [:entry_time, :signal_type], unique: true, name: :idx_sp_entry_time_type
   ```

   Repeat the pattern for indicator tables, storing floating values as `decimal` or `double precision` depending on downstream analytics needs. Use `integer` columns for enumerations and booleans for the various `_is_` flags.

5. **Associations.**
   ```ruby
   class MarketDataset < ApplicationRecord
     self.primary_key = :id
     has_many :signals, dependent: :destroy
   end

   class Signal < ApplicationRecord
     belongs_to :market_dataset
     has_many :bands_percent_snapshots,
              class_name: 'BandsPercent',
              foreign_key: :signal_id,
              dependent: :destroy
     # Repeat for other indicator tables
   end
   ```

6. **Data migration pipeline.**
   - Export SQLite to a CSV per table (`sqlite3 file.sqlite ".headers on" ".mode csv" "SELECT * FROM Table"`).
   - Use Rails `activerecord-import` or native `COPY` to bulk load into PostgreSQL.
   - Remember to disable triggers or deferred constraints during the load for speed, then re-enable and validate.

7. **Testing parity.**
   - Run sanity queries after import (row counts, min/max timestamps, constraint checks).
   - Mirror the EA's transactional save: wrap each signal and its dependents inside a PostgreSQL transaction to maintain atomicity.

## Database Query Reference

The following SQLite queries are still valid for PostgreSQL with minor syntax adjustments (e.g., use `TO_TIMESTAMP` in PostgreSQL instead of `datetime`).

### Count Total Signals
```sql
SELECT COUNT(*) FROM SignalParamsDB;
```

### Get Bullish Signals by Symbol
```sql
SELECT sp.*, md.symbol, md.name
FROM SignalParamsDB sp
JOIN MarketDatasetsDB md ON sp.dataset_id = md.dataset_id
WHERE sp.signal_type = 1
AND md.symbol = 'XAUUSD';
```

### Analyze Stochastic at Entry
```sql
SELECT
  sp.entry_time,
  sp.signal_type,
  s.stochastic_0,
  s.stochastic_signal_0,
  sp.raw_profit
FROM SignalParamsDB sp
JOIN StochasticDB s ON sp.signal_id = s.signal_id
WHERE s.timeframe = 1 AND s.period = 13
ORDER BY sp.entry_time DESC;
```

### Analyze BB% with Raw OHLC Prices
```sql
SELECT
  sp.entry_time,
  sp.signal_type,
  bp.bands_percent_0,
  bp.bb_close_0,
  bp.bb_open_0,
  bp.bb_high_0,
  bp.bb_low_0,
  sp.raw_profit
FROM SignalParamsDB sp
JOIN BandsPercentDB bp ON sp.signal_id = bp.signal_id
WHERE bp.timeframe = 1 AND bp.period = 21
ORDER BY sp.entry_time DESC;
```

### Analyze Body MA Momentum
```sql
SELECT
  sp.entry_time,
  sp.signal_type,
  bm.body_value_0,
  bm.body_ma_0,
  bm.body_trend_0,
  bm.body_ma_state_0,
  sp.raw_profit
FROM SignalParamsDB sp
JOIN BodyMADB bm ON sp.signal_id = bm.signal_id
WHERE bm.timeframe = 1 AND bm.period = 5
ORDER BY sp.entry_time DESC;
```

### Get Complete Signal Data for Machine Learning
```sql
SELECT
  md.symbol,
  md.name,
  sp.signal_type,
  sp.entry_time,
  sp.entry_price,
  sp.raw_profit,
  bp.bands_percent_0,
  bp.bands_percent_1,
  bp.bands_percent_2,
  bp.bands_percent_3,
  bp.bb_close_0,
  bp.bb_open_0,
  bp.bb_high_0,
  bp.bb_low_0,
  s.stochastic_0,
  s.stochastic_signal_0,
  sm.first_structure_type,
  sm.first_fibonacci_level,
  bm.body_value_0,
  bm.body_ma_0,
  bm.body_trend_0,
  bm.body_ma_state_0
FROM SignalParamsDB sp
JOIN MarketDatasetsDB md ON sp.dataset_id = md.dataset_id
JOIN BandsPercentDB bp ON sp.signal_id = bp.signal_id
JOIN StochasticDB s ON sp.signal_id = s.signal_id
JOIN StochasticMarketStructureDB sm ON sp.signal_id = sm.signal_id
JOIN BodyMADB bm ON sp.signal_id = bm.signal_id
WHERE bp.timeframe = 1 AND bp.period = 21
  AND s.timeframe = 1 AND s.period = 5
  AND sm.timeframe = 1 AND sm.period = 5
  AND bm.timeframe = 1 AND bm.period = 5
ORDER BY sp.entry_time DESC;
```

### Query Extremum Statistics (NEW - v1.10)
```sql
-- Get all extrema for a specific signal
SELECT
  extremum_index,
  datetime(extremum_time, 'unixepoch') as extremum_datetime,
  extremum_price,
  CASE WHEN is_peak = 1 THEN 'Peak' ELSE 'Bottom' END as type,
  intern_fibo_level,
  intern_is_extension,
  extern_fibo_level,
  extern_structures_broken,
  CASE structure_type
    WHEN 0 THEN 'EQ'
    WHEN 1 THEN 'HH'
    WHEN 2 THEN 'HL'
    WHEN 3 THEN 'LH'
    WHEN 4 THEN 'LL'
  END as structure
FROM ExtremumStatisticsDB
WHERE signal_id = 1 AND timeframe = 1 AND period = 5
ORDER BY extremum_index;
```

### Find Strong Extensions (INTERN >150%)
```sql
SELECT
  sp.entry_time,
  sp.signal_type,
  es.extremum_index,
  es.extremum_price,
  es.intern_fibo_level,
  es.extern_structures_broken,
  sp.raw_profit
FROM SignalParamsDB sp
JOIN ExtremumStatisticsDB es ON sp.signal_id = es.signal_id
WHERE es.timeframe = 1 
  AND es.period = 5
  AND es.intern_fibo_level > 150.0
  AND es.intern_is_extension = 1
ORDER BY es.intern_fibo_level DESC;
```

### Analyze Breakout Strength
```sql
SELECT
  sp.entry_time,
  sp.signal_type,
  es.extremum_price,
  es.extern_structures_broken,
  es.extern_fibo_level,
  sp.raw_profit
FROM SignalParamsDB sp
JOIN ExtremumStatisticsDB es ON sp.signal_id = es.signal_id
WHERE es.timeframe = 1 
  AND es.period = 5
  AND es.extern_is_active = 1
  AND es.extern_structures_broken >= 3
ORDER BY es.extern_structures_broken DESC;
```

### Compare Summary vs Detailed View
```sql
-- Get summary from old table
SELECT 
  signal_id,
  first_structure_type,
  second_structure_type,
  first_fibonacci_level
FROM StochasticMarketStructureDB
WHERE signal_id = 1 AND timeframe = 1 AND period = 5;

-- Get detailed extrema from new table
SELECT 
  extremum_index,
  structure_type,
  intern_fibo_level,
  extern_fibo_level
FROM ExtremumStatisticsDB
WHERE signal_id = 1 AND timeframe = 1 AND period = 5
ORDER BY extremum_index;
```

## How It Works

### Signal Detection Logic

**Bullish Signal:**
- Detected when Stochastic signal line (bar 1) <= 30 (oversold)
- Records entry at current ASK price
- Stores all indicator data at the moment of detection

**Bearish Signal:**
- Detected when Stochastic signal line (bar 1) >= 70 (overbought)
- Records entry at current BID price
- Stores all indicator data at the moment of detection

**Data Timing Logic:**
- `entry_time` is captured at the moment of signal detection (current candle open time)
- All indicator values (`_0`, `_1`, `_2`, `_3`) are fetched based on the entry_time candle, not the current candle
- This ensures historical accuracy: if a signal is logged/stored later, the data still reflects the exact market conditions at entry_time
- The system calculates the correct shift for each timeframe to match the entry_time candle
- Example: If entry_time = 00:03 and we log at 00:04, the system uses shift=1 to get 00:03 data (not shift=0 which would be 00:04)

### Data Flow

1. **OnInit()**:
   - Initialize database connection
   - Create/verify database tables
   - Load all indicator handles across timeframes
   - Insert dataset record

2. **OnTick()**:
   - Check spread limits (Max_Spread parameter)
   - Verify market is open
   - On new bar: Detect bullish/bearish signals
   - On every tick: Manage open signals (1-minute duration)

3. **Signal Lifecycle**:
   - Detection → Create SignalParams structure
   - Populate indicator data from all timeframes/periods
   - Add to running signals array
   - Monitor for 1 minute duration
   - Close signal and calculate profit
   - Store complete signal transaction to database

4. **OnDeinit()**:
   - Close database connection gracefully

## Installation

1. Place `Market_Scraper_Data_EA.mq5` in your MetaTrader 5 Experts folder:
   ```
   [Terminal_Data]/MQL5/Experts/Market_Scraper_Data/
   ```

2. Ensure all service files are in the correct subdirectories:
   ```
   services/
   ├── frontend/
   ├── trading_database/
   ├── trading_management/
   ├── trading_signals/
   └── trading_tools/
   ```

3. Required custom indicators in `[Terminal_Data]/MQL5/Indicators/Examples/`:
   - `BB_Standard.ex5`
   - `BB_Percent_Standard.ex5`
   - `Stochastic.ex5`
   - `Stochastic_Structure.ex5`
   - `Body_MA.ex5`

4. Compile the EA in MetaEditor

## Configuration

### Input Parameters

**EA Settings:**
- `EA_License_Key`: License key (optional, for future use)
- `Database_System_Name`: Unique name for this dataset (e.g., "BINARY_XAUUSD")
- `Database_System_Notes`: Description of the data collection strategy

**Account Settings:**
- `Account_Size`: Reference account size (default: 1200)
- `Custom_Magic`: Custom magic number (0 = auto-generate)
- `Max_Spread`: Maximum allowed spread in points (default: 15)
- `Min_Range_Points`: Minimum range in points (default: 15)

**Developer Settings:**
- `Test_Mode`: Reduces indicators loaded for faster testing (default: false)
- `Hide_Indicator_Variants`: Hide indicators from chart (default: true)
- `Enable_Logs`: Enable detailed logging (default: true)
- `Enable_Verification_Logs`: Enable detailed verification logs for data timing (default: false)

## Usage

1. **Attach to Chart**:
   - Open any chart (symbol will be used for data collection)
   - Drag the EA onto the chart
   - Configure input parameters
   - Enable AutoTrading

2. **Database Location**:
   - SQLite database is created in: `[Terminal_Data]/MQL5/Files/Common/`
   - Filename: `{Database_System_Name}_db.sqlite`

3. **Monitoring**:
   - Chart comment shows: "Enabled/Disabled / Magic: {number}"
   - Check Experts log for indicator loading and signal storage

4. **Data Analysis**:
   - Use SQLite browser tools to query the database
   - Export data for machine learning pipelines
   - Analyze patterns and correlations

## Project Structure

```
Market_Scraper_Data/
├── Market_Scraper_Data_EA.mq5          # Main EA file
├── README.md                            # This file
├── .gitignore                          # Git ignore rules
├── .github/
│   └── copilot-instructions.md         # AI coding guidelines
└── services/                           # Modular services
    ├── frontend/                       # UI components
    │   └── ea_license_light_version.mqh
    ├── trading_database/               # Database operations
    │   ├── initial_database_setup.mqh
    │   └── database_signal_wrapper.mqh
    ├── trading_management/             # Market analysis
    │   ├── indicator_definitions_loader.mqh
    │   └── market_conditions_functions.mqh
    ├── trading_signals/                # Signal detection
    │   ├── market_signal_crawler.mqh
    │   ├── signal_params_struct.mqh
    │   └── tick_signals_manager.mqh
    └── trading_tools/                  # Utility functions
        ├── array_functions.mqh
        ├── base_structures.mqh
        ├── logs_helper.mqh
        ├── miscelaneos.mqh
        ├── money_functions.mqh
        └── signal_enums.mqh
```

## Development Guidelines

### MQL5 Conventions
- **No C++11 features**: No `auto`, lambdas, references, heavy templates
- **Code style**: 2-space indent, `snake_case` variables, `CamelCase` functions
- **Modularity**: One file = one responsibility
- **Include paths**:
  - Standard libraries: `#include <Library/File.mqh>`
  - Custom services: `#include "services/module/file.mqh"`

### Database Best Practices
- Use transactions for multi-table inserts
- Check for existing records before inserting
- Enable WAL mode for concurrent access
- Use prepared statements (via DatabasePrepare)
- Proper error handling with GetLastError()

### Testing Considerations
- MQL5 does not support traditional unit tests
- Test in Strategy Tester with historical data
- Use `Test_Mode` to reduce indicator load during development
- Monitor database file size and growth rate


## Troubleshooting

**Issue: EA not detecting signals**
- Check spread is below Max_Spread
- Verify market is open
- Ensure indicators are loaded (check Experts log)

**Issue: Database errors**
- Verify write permissions in Common files folder
- Check disk space availability
- Review GetLastError() output in logs

**Issue: Indicators not loading**
- Confirm custom indicators are compiled (.ex5 files)
- Check indicator paths in indicator_definitions_loader.mqh
- Verify indicator parameters match expected format

## License & Copyright

All rights reserved for Traders Capital Team.
This EA is proprietary software. Unauthorized distribution or modification is prohibited.

For support, contact: @loldlm

---

**Disclaimer**: This EA is designed for data collection purposes. It does not execute actual trades. Use collected data responsibly and ensure compliance with your broker's data usage policies.
